{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AIM : To implement Recurrent Neural Network for sentiment analysis\n",
    "\n",
    "**Name : Trideep Nandi**\n",
    "\n",
    "**Class : CS4**\n",
    "\n",
    "**Batch: 2**\n",
    "\n",
    "**Enrollment : 0827CS211248**"
   ],
   "metadata": {
    "id": "sj9sgAvamk85"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Demonstration of RNN Architecure\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a type of artificial neural network designed to recognize patterns in sequences of data, such as text, genomes, handwriting, or the spoken word. Here are some key points about RNNs:\n",
    "\n",
    "1. **Sequence Processing:** RNNs are used for input sequences, output sequences, or both. They can process data of variable length, unlike other neural networks which require fixed length inputs and outputs.\n",
    "\n",
    "2. **Memory:** RNNs have \"memory\" in the form of hidden states that capture information about what has been calculated so far. This is particularly useful when the current output depends on the previous inputs.\n",
    "\n",
    "3. **Backpropagation Through Time:** RNNs learn to map inputs to outputs through a variant of backpropagation called backpropagation through time (BPTT).\n",
    "\n",
    "4. **Vanishing and Exploding Gradients:** RNNs can suffer from vanishing and exploding gradient problems, making them hard to train for long sequences.\n",
    "\n",
    "5. **Gated Cells:** To overcome the issues with traditional RNNs, variants such as Long Short-Term Memory (LSTM) and Gated Recurrent Units (GRU) have been developed. These variants have gating mechanisms that control the flow of information to and from the memory cell.\n",
    "\n",
    "RNNs are used in a variety of applications including:\n",
    "\n",
    "- **Natural Language Processing (NLP):** RNNs are used for language modeling, machine translation, text generation, and sentiment analysis.\n",
    "\n",
    "- **Speech Recognition:** RNNs can be used to convert spoken language into written form.\n",
    "\n",
    "- **Time Series Prediction:** RNNs can predict future values of a time series like stock prices or weather patterns.\n",
    "\n",
    "- **Music Composition:** RNNs can generate music by learning patterns in musical sequences.\n",
    "\n",
    "- **Gesture Recognition:** RNNs can recognize patterns in sequences of movements for gesture-based control systems."
   ],
   "metadata": {
    "id": "hjZkhvZ6mnwE"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below imports the Sequential model class from Keras, which is used to create a linear stack of layers, and the Dense and SimpleRNN layer classes, which are used to create fully connected and simple recurrent layers respectively."
   ],
   "metadata": {
    "id": "NTi9IR5emrj0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3LQz13MyYhez"
   },
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below creates a Sequential model in Keras with a Simple Recurrent Neural Network (RNN) layer having 3 neurons and an input shape of (4,5), followed by a Dense output layer with 1 neuron and a sigmoid activation function."
   ],
   "metadata": {
    "id": "Dm2miZpmmtrf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model=Sequential()\n",
    "model.add(SimpleRNN(3,input_shape=(4,5)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n"
   ],
   "metadata": {
    "id": "yz1zlPJMYscL"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The model.summary() code prints a summary representation of your model, showing the layer types, output shapes, and the number of parameters, both trainable and non-trainable."
   ],
   "metadata": {
    "id": "0GcwvV5Jmwc5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kOIAUzKmYtYD",
    "outputId": "1a343532-6db7-4307-f23b-cc59c5a13124"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 27        \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 4         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31 (124.00 Byte)\n",
      "Trainable params: 31 (124.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This output shows the summary of the Sequential model, indicating it has two layers - a SimpleRNN layer with 3 neurons (27 parameters) and a Dense layer with 1 neuron (4 parameters), totaling to 31 trainable parameters and no non-trainable parameters."
   ],
   "metadata": {
    "id": "HXt7-yQkmyo7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below prints the shape of the weight matrix of the first layer in the model (SimpleRNN layer) and then returns the actual weight values of that layer."
   ],
   "metadata": {
    "id": "N-VtssYVm2yV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.get_weights()[0].shape)\n",
    "model.get_weights()[0]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZzdckBtY1h7",
    "outputId": "f136b506-6ee5-4116-8649-74bbf5623a07"
   },
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.48222476,  0.3212604 ,  0.09172821],\n",
       "       [-0.07115531, -0.6588487 , -0.72447187],\n",
       "       [ 0.75353223, -0.23280686,  0.8544466 ],\n",
       "       [-0.51625884, -0.43121096,  0.6041532 ],\n",
       "       [-0.13687783, -0.00232309,  0.7819211 ]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below prints the shape of the recurrent weight matrix of the first layer in the model (SimpleRNN layer) and then returns the actual recurrent weight values of that layer."
   ],
   "metadata": {
    "id": "MBqTVnmUm7Gw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.get_weights()[1].shape)\n",
    "model.get_weights()[1]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "igl47LTfY5jD",
    "outputId": "be8ef17b-7599-496e-b69f-30afe5b33d2e"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.47776914,  0.5143387 , -0.7121744 ],\n",
       "       [-0.875431  ,  0.21120954, -0.43475407],\n",
       "       [-0.07319281,  0.8311717 ,  0.55117744]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below prints the shape of the bias vector of the first layer in the model (SimpleRNN layer) and then returns the actual bias values of that layer."
   ],
   "metadata": {
    "id": "8Ta6pOuUm9Iv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.get_weights()[2].shape)\n",
    "model.get_weights()[2]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BqM9QjRAY-n0",
    "outputId": "be949f94-b4cb-4b43-fc73-c09962c72c55"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0., 0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below prints the shape of the weight matrix of the second layer in the model (Dense layer) and then returns the actual weight values of that layer."
   ],
   "metadata": {
    "id": "2x6b1zBbm_GE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.get_weights()[3].shape)\n",
    "model.get_weights()[3]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffRW4c7pZBCq",
    "outputId": "0389c4b9-63d6-4b31-fdbb-b1e0e23ddd4d"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.046249 ],\n",
       "       [1.1538934],\n",
       "       [0.7615069]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The code below prints the shape of the bias vector of the second layer in the model (Dense layer) and then returns the actual bias values of that layer."
   ],
   "metadata": {
    "id": "Srn8tcVanBP_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.get_weights()[4].shape)\n",
    "model.get_weights()[4]\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hViPjQj2ZDwi",
    "outputId": "7918eb56-6e2b-4443-bf23-4778ea75ec78"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Integer Encoding\n",
    "\n",
    "Integer encoding is a method of converting categorical data, specifically text data, into numerical form so that it can be used by a machine learning algorithm. In integer encoding, each unique word is represented by a unique integer. For example, in a list of words ['apple', 'banana', 'apple', 'cherry'], the integer encoded form could be [1, 2, 1, 3]. This method is often used in natural language processing tasks."
   ],
   "metadata": {
    "id": "8upb5b2SZP6z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np"
   ],
   "metadata": {
    "id": "1eqbPTmPZOrz"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below line of code is creating a list named `docs` in Python. The list contains 10 strings, each of which appears to be a phrase or sentence. This list could be used for various purposes, such as text processing, natural language processing, or other forms of analysis."
   ],
   "metadata": {
    "id": "icQlgfhbnREA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "docs = ['go india',\n",
    "'india india',\n",
    "'hip hip hurray',\n",
    "'jeetega bhai jeetega india jeetega',\n",
    "'bharat mata ki jai',\n",
    "'kohli kohli',\n",
    "'sachin sachin',\n",
    "'dhoni dhoni',\n",
    "'modi ji ki jai',\n",
    "'inquilab zindabad']\n"
   ],
   "metadata": {
    "id": "oi91rqbBZXQL"
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code creates a Keras Tokenizer object with a specified out-of-vocabulary token, fits it on the provided documents, displays the word index, word counts, and document count, then converts the documents into sequences of integers representing the words based on the fitted tokenizer."
   ],
   "metadata": {
    "id": "wqj2pBXsnz3q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(oov_token='<nothing>')\n",
    "tokenizer.fit_on_texts(docs)\n",
    "tokenizer.word_index\n",
    "tokenizer.word_counts\n",
    "tokenizer.document_count\n",
    "sequences = tokenizer.texts_to_sequences(docs)\n",
    "sequences\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCqs90itZYSK",
    "outputId": "3ccdcf56-879f-4b1c-b204-6372522a2956"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[10, 2],\n",
       " [2, 2],\n",
       " [4, 4, 11],\n",
       " [3, 12, 3, 2, 3],\n",
       " [13, 14, 5, 6],\n",
       " [7, 7],\n",
       " [8, 8],\n",
       " [9, 9],\n",
       " [15, 16, 5, 6],\n",
       " [17, 18]]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code uses Keras's `pad_sequences` function to pad the sequences of integers representing the words to the same length by adding zeros at the end of each sequence (post-padding)."
   ],
   "metadata": {
    "id": "qSQkTLhSn62l"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from keras.utils import pad_sequences\n",
    "sequences = pad_sequences(sequences,padding='post')\n",
    "sequences"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6PSiVc3JZbFT",
    "outputId": "939146c1-0d29-4df1-f11f-17fe36f09630"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[10,  2,  0,  0,  0],\n",
       "       [ 2,  2,  0,  0,  0],\n",
       "       [ 4,  4, 11,  0,  0],\n",
       "       [ 3, 12,  3,  2,  3],\n",
       "       [13, 14,  5,  6,  0],\n",
       "       [ 7,  7,  0,  0,  0],\n",
       "       [ 8,  8,  0,  0,  0],\n",
       "       [ 9,  9,  0,  0,  0],\n",
       "       [15, 16,  5,  6,  0],\n",
       "       [17, 18,  0,  0,  0]], dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  }
 ]
}
