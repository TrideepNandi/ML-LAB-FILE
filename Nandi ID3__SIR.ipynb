{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AIM : Decision Tree ID3 Algorithm \n",
    "\n",
    "**Name : Trideep Nandi**\n",
    "\n",
    "**Class : CS4**\n",
    "\n",
    "**Batch: 2**\n",
    "\n",
    "**Enrollment : 0827CS211248**"
   ],
   "metadata": {
    "id": "X0hKtFJRYMQa"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYLc_eBE1rvB"
   },
   "source": [
    "**Step by Step Decision Tree: ID3 Algorithm**\n",
    "**Objectives:**\n",
    "1. Knowing the basics of the ID3 Algorithm\n",
    "2. Loading csv data in python, (using pandas library)\n",
    "3. Training and building Decision tree using ID3 algorithm\n",
    "4. Predicting from the tree\n",
    "5. Finding out the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE3hdF1A2GQf"
   },
   "source": [
    "**Step 1: Observing The dataset**\n",
    "\n",
    "https://www.kaggle.com/tareqjoy/trainplaytennis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRJ08XVP3Nqw"
   },
   "source": [
    "**Step 2: Importing the necessary basic python libraries**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iuilWBoAYO1A",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:12:29.909815Z",
     "start_time": "2024-05-07T07:12:28.909067Z"
    }
   },
   "source": [
    "import pandas as pd #for manipulating the csv data\n",
    "import numpy as np #for mathematical calculation"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bcoc124N1tKT"
   },
   "source": [
    "**Step 3: Reading the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "r0wTwTkHYaFg",
    "outputId": "5f719128-91e3-4544-ce7f-9a560480b818",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:15:33.719735Z",
     "start_time": "2024-05-07T07:15:33.695263Z"
    }
   },
   "source": [
    "train_data_m = pd.read_csv(\"content/PlayTennis.csv\") #reading the dataset\n",
    "\n",
    "train_data_m.head() #viewing some row of the dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Outlook Temperature Humidity    Wind Play Tennis\n",
       "0     Sunny         Hot     High    Weak          No\n",
       "1     Sunny         Hot     High  Strong          No\n",
       "2  Overcast         Hot     High    Weak         Yes\n",
       "3      Rain        Mild     High    Weak         Yes\n",
       "4      Rain        Cool   Normal    Weak         Yes"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outlook</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind</th>\n",
       "      <th>Play Tennis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunny</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Strong</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overcast</td>\n",
       "      <td>Hot</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Mild</td>\n",
       "      <td>High</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rain</td>\n",
       "      <td>Cool</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Weak</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDIFxUtm1vN2"
   },
   "source": [
    "**Step 4: Calculating the entropy of the whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sm0g81cCY4_y",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:15:46.718002Z",
     "start_time": "2024-05-07T07:15:46.711573Z"
    }
   },
   "source": [
    "def calc_total_entropy(train_data, label, class_list):\n",
    "    total_row = train_data.shape[0] #the total size of the dataset\n",
    "    total_entr = 0\n",
    "\n",
    "    for c in class_list: #for each class in the label\n",
    "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
    "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
    "        total_entr += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
    "\n",
    "    return total_entr"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtXMvdWX1wmt"
   },
   "source": [
    "**Step 5: Calculating the entropy for the filtered dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this function is to calculate the total entropy of a dataset based on the given label and class list.\n",
    "\n",
    "Parameters:\n",
    "1. train_data: A pandas DataFrame representing the training dataset.\n",
    "2. label: A string representing the name of the column that contains the label or target variable.\n",
    "3. class_list: A list containing the unique class values present in the label column."
   ],
   "metadata": {
    "id": "p6kzDyZzYshW"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rVYzEk-o3H46",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:15:55.682352Z",
     "start_time": "2024-05-07T07:15:55.674154Z"
    }
   },
   "source": [
    "def calc_entropy(feature_value_data, label, class_list):\n",
    "    class_count = feature_value_data.shape[0]\n",
    "    entropy = 0\n",
    "\n",
    "    for c in class_list:\n",
    "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c\n",
    "        entropy_class = 0\n",
    "        if label_class_count != 0:\n",
    "            probability_class = label_class_count/class_count #probability of the class\n",
    "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
    "        entropy += entropy_class\n",
    "    return entropy"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bc2aZU2M1yPq"
   },
   "source": [
    "**Step 6: Calculating information gain for a feature**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this function is to calculate the entropy of a feature value (subset of data) based on the given label and class list.\n",
    "\n",
    "Parameters:\n",
    "1. feature_value_data: A pandas DataFrame representing a subset of the training data for a specific feature value.\n"
   ],
   "metadata": {
    "id": "-2RvQHmvY2nW"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jQSpLqSkZGvS",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:16:07.048308Z",
     "start_time": "2024-05-07T07:16:07.040946Z"
    }
   },
   "source": [
    "def calc_info_gain(feature_name, train_data, label, class_list):\n",
    "    feature_value_list = train_data[feature_name].unique() #unqiue values of the feature\n",
    "    total_row = train_data.shape[0]\n",
    "    feature_info = 0.0\n",
    "\n",
    "    for feature_value in feature_value_list:\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #filtering rows with that feature_value\n",
    "        feature_value_count = feature_value_data.shape[0]\n",
    "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) #calculcating entropy for the feature value\n",
    "        feature_value_probability = feature_value_count/total_row\n",
    "        feature_info += feature_value_probability * feature_value_entropy #calculating information of the feature value\n",
    "\n",
    "    return calc_total_entropy(train_data, label, class_list) - feature_info #calculating information gain by subtracting"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3DU9mr91z8Y"
   },
   "source": [
    "**Step 8: Adding a node to the tree**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B91hvAkoZcaU",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:22:52.951522Z",
     "start_time": "2024-05-07T07:22:52.942215Z"
    }
   },
   "source": [
    "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
    "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
    "    tree = {} #sub tree or node\n",
    "\n",
    "    for feature_value, count in feature_value_count_dict.items():\n",
    "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
    "\n",
    "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
    "        for c in class_list: #for each class\n",
    "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
    "\n",
    "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
    "                tree[feature_value] = c #adding node to the tree\n",
    "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
    "                assigned_to_node = True\n",
    "        if not assigned_to_node: #not pure class\n",
    "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further,\n",
    "                                      #so the branch is marking with ?\n",
    "\n",
    "    return tree, train_data"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0eFYSL611Wb"
   },
   "source": [
    "**Step 7: Finding the most informative feature (feature with highest information gain)**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The purpose of this function is to generate a sub-tree (or node) for a specific feature in a decision tree.\n",
    "\n",
    "Parameters:\n",
    "1. feature_name: A string representing the name of the feature for which the sub-tree is being generated.\n",
    "2. train_data: A pandas DataFrame representing the training dataset.\n",
    "3. label: A string representing the name of the column that contains the label or target variable.\n",
    "4. class_list: A list containing the unique class values present in the label column.\n",
    "5. Feature Value Count Dictionary:\n",
    "The function first creates a dictionary (feature_value_count_dict) that counts the occurrences of each unique feature value in the given feature column (feature_name).\n",
    "6. Sub-Tree Generation:\n",
    "For each unique feature value, the function creates a subset of the training data where the feature value matches the current unique value. Then it\n",
    "Checks if the subset is a pure class (i.e., all instances in the subset belong to the same class).\n",
    "Result:\n",
    "The function returns a dictionary (tree) representing the sub-tree for the given feature. Each key in the dictionary corresponds to a unique feature value, and the value associated with that key can be either a class label or “?” (indicating further branching)."
   ],
   "metadata": {
    "id": "Zw7xIy3dZd55"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LbIDlcM85u-x",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:16:46.395553Z",
     "start_time": "2024-05-07T07:16:46.387028Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    " feature_value_list = ['Outlook','Wind', 'Temperature', 'Humidity']\n",
    " dict = {}\n",
    " for i in feature_value_list:\n",
    "   dict[i]=calc_info_gain(i,train_data,label,class_list)\n",
    " v = list(dict.values())\n",
    " k = list(dict.keys())\n",
    " return(k[v.index(max(v))])\n",
    "\"\"\"\n",
    "def find_most_informative_feature(train_data, label, class_list):\n",
    "  feature_list = train_data.columns.drop(label) #finding the feature names in the dataset\n",
    "                                            #N.B. label is not a feature, so dropping it\n",
    "  max_info_gain = -1\n",
    "  max_info_feature = None\n",
    "\n",
    "  for feature in feature_list:  #for each feature in the dataset\n",
    "      feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
    "      if max_info_gain < feature_info_gain: #selecting feature name with highest information gain\n",
    "          max_info_gain = feature_info_gain\n",
    "          max_info_feature = feature\n",
    "\n",
    "  return max_info_feature"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNBHBkT012ms"
   },
   "source": [
    "**Step 9: Performing ID3 Algorithm and generating Tree**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function will now generate tree using ID3 decision tree algorithm."
   ],
   "metadata": {
    "id": "QC13svxmZ2G0"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rm65QUUMZlaT",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:17:50.892965Z",
     "start_time": "2024-05-07T07:17:50.884711Z"
    }
   },
   "source": [
    "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
    "    if train_data.shape[0] != 0: #if dataset becomes empty after updating\n",
    "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
    "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
    "        next_root = None\n",
    "\n",
    "        if prev_feature_value != None: #add to intermediate node of the tree\n",
    "            root[prev_feature_value] = dict()\n",
    "            root[prev_feature_value][max_info_feature] = tree\n",
    "            next_root = root[prev_feature_value][max_info_feature]\n",
    "        else: #add to root of the tree\n",
    "            root[max_info_feature] = tree\n",
    "            next_root = root[max_info_feature]\n",
    "\n",
    "        for node, branch in list(next_root.items()): #iterating the tree node\n",
    "            if branch == \"?\": #if it is expandable\n",
    "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
    "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlzctkjq14c9"
   },
   "source": [
    "**Step 10: Finding unique classes of the label and Starting the algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u2lgAnk2ZraP",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:17:54.936401Z",
     "start_time": "2024-05-07T07:17:54.928584Z"
    }
   },
   "source": [
    "def id3(train_data_m, label):\n",
    "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
    "    tree = {} #tree which will be updated\n",
    "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
    "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
    "    return tree"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvJjLiVQ4rgB"
   },
   "source": [
    "**Starting the algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "08bdc10f-c6bb-4c51-b6b8-b90f975c1904",
    "id": "WOKoIwPiIe_3",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:23:15.798255Z",
     "start_time": "2024-05-07T07:23:15.738614Z"
    }
   },
   "source": [
    "tree = id3(train_data_m, 'Play Tennis')\n",
    "print(tree)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}, 'Overcast': 'Yes', 'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZWC6G4E18TZ"
   },
   "source": [
    "**Step 11: Predicting from the tree**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dnB0F_GudrJ-",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:57:55.765033Z",
     "start_time": "2024-05-07T07:57:55.760613Z"
    }
   },
   "source": [
    "def predict(tree, instance):\n",
    "    if not isinstance(tree, dict): #if it is leaf node\n",
    "        return tree #return the value\n",
    "    else:\n",
    "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
    "        feature_value = instance[root_node] #value of the feature\n",
    "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
    "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
    "        else:\n",
    "            return None"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQGJJ4-O1--z"
   },
   "source": [
    "**Step 12: Evaluating test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oM7HIt1teDWg",
    "ExecuteTime": {
     "end_time": "2024-05-07T07:57:59.274472Z",
     "start_time": "2024-05-07T07:57:59.270685Z"
    }
   },
   "source": [
    "def evaluate(tree, test_data_m, label):\n",
    "    correct_predict = 0\n",
    "    wrong_predict = 0\n",
    "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
    "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
    "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
    "            correct_predict += 1 #increase correct count\n",
    "        else:\n",
    "            wrong_predict += 1 #increase incorrect count\n",
    "    accuracy = correct_predict / (correct_predict + wrong_predict) #calculating accuracy\n",
    "    return accuracy"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
